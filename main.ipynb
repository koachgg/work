{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\beloabhigyan\\documents\\ir systems\\myenv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\beloabhigyan\\documents\\ir systems\\myenv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\beloabhigyan\\documents\\ir systems\\myenv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\beloabhigyan\\documents\\ir systems\\myenv\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\beloabhigyan\\documents\\ir systems\\myenv\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import qdrant_client\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import ndcg_score\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.exceptions import UnexpectedResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = \"http://192.68.10.50:6333\"\n",
    "client = QdrantClient(url=QDRANT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {q[\"_id\"]: q[\"text\"] for q in map(json.loads, open(\"queries.jsonl\"))}\n",
    "corpus = {c[\"_id\"]: c[\"text\"] for c in map(json.loads, open(\"SciFact.jsonl\"))} # corpus.jsonl\n",
    "qrels = pd.read_csv(\"train.tsv\", sep=\"\\t\", names=[\"query-id\", \"corpus-id\", \"score\"]) #qrels/train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query-id' '0' '2' '4' '6' '9' '10' '11' '12' '14']\n"
     ]
    }
   ],
   "source": [
    "print(qrels[\"query-id\"].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10 queries for evaluation\n",
    "selected_queries = qrels[\"query-id\"].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(query_text, k=10):\n",
    "    \"\"\"Retrieve top-k results from Qdrant for a given query.\"\"\"\n",
    "    query_vector = model.encode(query_text).tolist()\n",
    "    results = client.search(collection_name=\"scifact\", query_vector=query_vector, limit=k)\n",
    "    return [r.payload[\"id\"] for r in results]  # Retrieve document IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(retrieved_docs, relevant_docs):\n",
    "    \"\"\"Compute DCG, NDCG, Recall@10, and MAP@10.\"\"\"\n",
    "    relevance_scores = [1 if doc in relevant_docs else 0 for doc in retrieved_docs]\n",
    "    \n",
    "    dcg = sum(rel / np.log2(i+2) for i, rel in enumerate(relevance_scores))\n",
    "    ideal_dcg = sum(1 / np.log2(i+2) for i in range(len(relevant_docs)))\n",
    "    ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "    \n",
    "    recall_at_10 = sum(relevance_scores) / len(relevant_docs)\n",
    "    \n",
    "    precisions = [sum(relevance_scores[:i+1]) / (i+1) for i in range(len(relevance_scores)) if relevance_scores[i] > 0]\n",
    "    map_at_10 = np.mean(precisions) if precisions else 0\n",
    "    \n",
    "    return dcg, ndcg, recall_at_10, map_at_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple evaluations to check determinism\n",
    "iterations = 3  # Can be increased to 5 later\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id in selected_queries:\n",
    "    query_text = queries.get(query_id, \"\")\n",
    "    relevant_docs = set(qrels[qrels[\"query-id\"] == query_id][\"corpus-id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BeloAbhigyan\\AppData\\Local\\Temp\\ipykernel_22332\\3409790786.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(collection_name=\"scifact\", query_vector=query_vector, limit=k)\n"
     ]
    }
   ],
   "source": [
    "def safe_retrieve_top_k(query_text, k=10, max_retries=3):\n",
    "    \"\"\"Wrapper for retrieve_top_k with error handling\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return retrieve_top_k(query_text, k)\n",
    "        except (requests.exceptions.ConnectionError, UnexpectedResponse) as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            time.sleep(1)  # Wait before retry\n",
    "\n",
    "# Modified query loop\n",
    "for query_id in selected_queries:\n",
    "    query_text = queries.get(query_id, \"\")\n",
    "    relevant_docs = set(qrels[qrels[\"query-id\"] == query_id][\"corpus-id\"])\n",
    "    \n",
    "    row = {\"Query ID\": query_id}\n",
    "    for i in range(iterations):\n",
    "        try:\n",
    "            retrieved_docs = safe_retrieve_top_k(query_text, k=10)\n",
    "            dcg, ndcg, recall, map_ = compute_metrics(retrieved_docs, relevant_docs)\n",
    "            row[f\"Iteration {i+1}\"] = f\"NDCG: {ndcg:.3f}, Recall@10: {recall:.3f}, MAP@10: {map_:.3f}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query {query_id}, iteration {i+1}: {e}\")\n",
    "            row[f\"Iteration {i+1}\"] = \"Error: Failed to retrieve results\"\n",
    "    \n",
    "    results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([Record(id=0, payload={'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'dataset_name': 'scifact'}, vector=None, shard_key=None, order_value=None)], 1)\n"
     ]
    }
   ],
   "source": [
    "print(client.scroll(collection_name=\"scifact\", limit=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server connection test: 200\n",
      "([Record(id=0, payload={'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'dataset_name': 'scifact'}, vector=None, shard_key=None, order_value=None)], 1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Test server availability first\n",
    "import requests\n",
    "import time\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.exceptions import UnexpectedResponse\n",
    "\n",
    "def test_qdrant_connection():\n",
    "    try:\n",
    "        response = requests.get(\"http://192.168.10.50:6333/collections\")\n",
    "        print(f\"Server connection test: {response.status_code}\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# 2. Initialize client with better settings\n",
    "if test_qdrant_connection():\n",
    "    client = QdrantClient(\n",
    "        url=\"http://192.168.10.50:6333\",\n",
    "        timeout=60.0,  # Increased timeout\n",
    "        prefer_grpc=False\n",
    "    )\n",
    "    \n",
    "    # 3. Try scrolling with error handling\n",
    "    try:\n",
    "        result = client.scroll(\n",
    "            collection_name=\"scifact\",\n",
    "            limit=1,\n",
    "            timeout=30\n",
    "        )\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scroll: {e}\")\n",
    "        print(\"Try using IP 127.0.0.1 instead of localhost\")\n",
    "else:\n",
    "    print(\"Could not connect to Qdrant server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8063697', '33934971', '27527854', '8069939', '25897733']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BeloAbhigyan\\AppData\\Local\\Temp\\ipykernel_22332\\3409790786.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(collection_name=\"scifact\", query_vector=query_vector, limit=k)\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the effect of vaccines?\"\n",
    "retrieved_docs = retrieve_top_k(test_query, k=5)\n",
    "print(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. Results saved to evaluation_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"evaluation_results.xlsx\", index=False)\n",
    "print(\"Evaluation completed. Results saved to evaluation_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query ID</th>\n",
       "      <th>Iteration 1</th>\n",
       "      <th>Iteration 2</th>\n",
       "      <th>Iteration 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query-id</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "      <td>Error: Failed to retrieve results</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query ID                        Iteration 1  \\\n",
       "0  query-id  Error: Failed to retrieve results   \n",
       "1         0  Error: Failed to retrieve results   \n",
       "2         2  Error: Failed to retrieve results   \n",
       "3         4  Error: Failed to retrieve results   \n",
       "4         6  Error: Failed to retrieve results   \n",
       "\n",
       "                         Iteration 2                        Iteration 3  \n",
       "0  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
       "1  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
       "2  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
       "3  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
       "4  Error: Failed to retrieve results  Error: Failed to retrieve results  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Query ID     16 non-null     object\n",
      " 1   Iteration 1  16 non-null     object\n",
      " 2   Iteration 2  16 non-null     object\n",
      " 3   Iteration 3  16 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 644.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(\"DataFrame Info:\")\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Query ID     16 non-null     object\n",
      " 1   Iteration 1  16 non-null     object\n",
      " 2   Iteration 2  16 non-null     object\n",
      " 3   Iteration 3  16 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 644.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate counts:\n",
      "Query ID\n",
      "query-id    3\n",
      "0           2\n",
      "2           2\n",
      "4           2\n",
      "6           2\n",
      "9           1\n",
      "10          1\n",
      "11          1\n",
      "12          1\n",
      "14          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDuplicate counts:\")\n",
    "print(df['Query ID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Rows:\n",
      "   Query ID                        Iteration 1  \\\n",
      "0  query-id  Error: Failed to retrieve results   \n",
      "1         0  Error: Failed to retrieve results   \n",
      "2         2  Error: Failed to retrieve results   \n",
      "3         4  Error: Failed to retrieve results   \n",
      "4         6  Error: Failed to retrieve results   \n",
      "\n",
      "                         Iteration 2                        Iteration 3  \n",
      "0  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
      "1  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
      "2  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
      "3  Error: Failed to retrieve results  Error: Failed to retrieve results  \n",
      "4  Error: Failed to retrieve results  Error: Failed to retrieve results  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
